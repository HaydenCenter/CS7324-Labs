{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab One: Exploring Table Data\n",
    "Team: Jack Babcock, Hayden Center, Fidelia Navar, Amory Weinzierl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assignment Description\n",
    "You are to perform preprocessing and exploratory analysis of a data set: exploring the statistical summaries of the features, visualizing the attributes, and addressing data quality. This report is worth 10% of the final grade. Please upload a report (one per team) with all code used, visualizations, and text in a rendered Jupyter notebook. Any visualizations that cannot be embedded in the notebook, please provide screenshots of the output.\n",
    "\n",
    "Additional information and requirements can be found at https://smu.instructure.com/courses/81978/assignments/465788"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part I -  Business Understanding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data set (which can be found at https://www.kaggle.com/fedesoriano/stroke-prediction-dataset) that we have chosen to utilize for this lab consists of data that may be used to identify whether or not an individual is at risk for strokes. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part II - Data Understanding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "print('Pandas:', pd.__version__)\n",
    "print('Numpy:',  np.__version__)\n",
    "\n",
    "df = pd.read_csv('healthcare-dataset-stroke-data.csv')\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Formatting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To clean up the data a little bit, we're going to normalize the values of the non-numeric columns to have the same format by setting all values to lowercase and replacing spaces with underscores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in df.columns:\n",
    "    if df[c].dtype == 'object':\n",
    "        df[c] = df[c].str.lower()\n",
    "        \n",
    "df = df.replace(' ', '_', regex=True)\n",
    "        \n",
    "for c in df.columns:\n",
    "    if df[c].dtype == 'object':\n",
    "        print(df[c].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All of the columns look good except for the smoking_status column. One of the values in that column is listed as 'unknown'. Though this is technically a value, what it is actually representing is missing information, so let's make that more clear."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.smoking_status.mask(df.smoking_status == 'unknown', np.nan, inplace=True)\n",
    "\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of the categorical columns should be converted into numerical columns. Specifically the ever_married column should be converted into a binary column similar to the hypertension, heart_disease, and stroke columns, and the smoking_status column should be converted into an ordinal. We think this is a meaningful change because there is a very clear way to assign an order to the values: never_smoked is 0, formerly_smoked is 1 since it is worse for your health, and finally smokes is 2, since it is worse than formerly_smoked."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.smoking_status.replace(to_replace= ['never_smoked', 'formerly_smoked', 'smokes'], value = [0, 1, 2], inplace=True)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(df[df.gender == 'other'].index, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Quality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Duplicate Values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first thing we'll want to do to check the quality of the data is to check for duplicates. First, let's make sure there are no duplicate IDs in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if df.id.unique().size == df.id.size:\n",
    "    print(\"No duplicate IDs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we know there are no duplicate IDs, let's check if there are any rows with identical values (excluding the ID)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = df.columns.drop('id')\n",
    "\n",
    "s = df.duplicated(subset=cols, keep='first')\n",
    "\n",
    "s[s]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seems like the dataset has no exact duplicates. We feel safe assuming that, finding no exact duplicates, each entry in the dataset is unique."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Missing Values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second thing to check the dataset for is missing values. We can see them by checking df.info()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This shows us that we're missing data from two columns: smoking_status and bmi. Now let's take a look at both of the columns with missing data and see if we want to impute or delete them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### BMI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first look at the inital data from the column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.bmi.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's attempt to impute the bmi column using KNNImputer with the numerical and boolean columns of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.impute import KNNImputer\n",
    "import copy\n",
    "\n",
    "knn = KNNImputer(n_neighbors=3)\n",
    "\n",
    "temp = df[[\n",
    "    'age',\n",
    "    'hypertension',\n",
    "    'heart_disease',\n",
    "    'avg_glucose_level',\n",
    "    'bmi',\n",
    "    'stroke'\n",
    "]].to_numpy()\n",
    "\n",
    "temp_imputed = knn.fit_transform(temp)\n",
    "\n",
    "df_imputed = copy.deepcopy(df)\n",
    "df_imputed[[\n",
    "    'age',\n",
    "    'hypertension',\n",
    "    'heart_disease',\n",
    "    'avg_glucose_level',\n",
    "    'bmi',\n",
    "    'stroke'\n",
    "]] = temp_imputed\n",
    "\n",
    "df_imputed.bmi = df_imputed.bmi.apply(lambda x: round(x, 1))\n",
    "print(\"----- Original -----\")\n",
    "print(df.bmi.describe())\n",
    "print(\"----- Imputed ------\")\n",
    "print(df_imputed.bmi.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the averages and five number summary of the dataset before and after the imputation, we see that there is very little difference. The dataset seemed to impute slightly more datapoints just above the mean and in a tighter grouping. Let's now visualize the imputation using a histogram."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.simplefilter('ignore', DeprecationWarning)\n",
    "%matplotlib inline \n",
    "\n",
    "df_imputed.bmi.plot(kind='hist', alpha=0.5, label=\"imputed\",bins=100)\n",
    "df.bmi.plot(kind='hist', alpha=0.5, label=\"original\",bins=100)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The imputation looks very successful from this visualization, so we have decided to use the imputed data for our visualizations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df = df_imputed\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### SMOKING_STATUS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first look at the inital data from the column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df.smoking_status.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's attempt to impute the smoking_status column using KNNImputer with the numerical and boolean columns of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.impute import KNNImputer\n",
    "import copy\n",
    "\n",
    "knn = KNNImputer(n_neighbors=3)\n",
    "\n",
    "temp = df[[\n",
    "    'age',\n",
    "    'hypertension',\n",
    "    'heart_disease',\n",
    "    'avg_glucose_level',\n",
    "    'smoking_status',\n",
    "    'stroke'\n",
    "]].to_numpy()\n",
    "\n",
    "temp_imputed = knn.fit_transform(temp)\n",
    "\n",
    "df_imputed = copy.deepcopy(df)\n",
    "df_imputed[[\n",
    "    'age',\n",
    "    'hypertension',\n",
    "    'heart_disease',\n",
    "    'avg_glucose_level',\n",
    "    'smoking_status',\n",
    "    'stroke'\n",
    "]] = temp_imputed\n",
    "\n",
    "df_imputed.smoking_status = df_imputed.smoking_status.apply(lambda x: round(x))\n",
    "print(\"----- Original -----\")\n",
    "print(df.smoking_status.describe())\n",
    "print(\"----- Imputed ------\")\n",
    "print(df_imputed.smoking_status.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.simplefilter('ignore', DeprecationWarning)\n",
    "%matplotlib inline \n",
    "\n",
    "df_imputed.smoking_status.plot(kind='hist', alpha=0.5, label=\"imputed\",bins=3)\n",
    "df.smoking_status.plot(kind='hist', alpha=0.5, label=\"original\",bins=3)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This imputation seems to be much less successful than the previous one, imputing significantly more non-smoking and former-smoking datapoints than smoking datapoints. However, taking into account both how large the population with missing data is, and also real world factors that may influence this distribution, we have decided to use this imputated data as well. Regarding the real world factors, it seems plausible that smokers are more likely to be recorded as smokers due to the relevance of smoking to general health, whereas former- or non-smokers might not have that data recorded as often."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part III - Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part IV - Exceptional Work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
