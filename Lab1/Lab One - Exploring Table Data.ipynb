{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab One: Exploring Table Data\n",
    "Team: Jack Babcock, Hayden Center, Fidelia Navar, Amory Weinzierl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assignment Description\n",
    "You are to perform preprocessing and exploratory analysis of a data set: exploring the statistical summaries of the features, visualizing the attributes, and addressing data quality. This report is worth 10% of the final grade. Please upload a report (one per team) with all code used, visualizations, and text in a rendered Jupyter notebook. Any visualizations that cannot be embedded in the notebook, please provide screenshots of the output.\n",
    "\n",
    "Additional information and requirements can be found at https://smu.instructure.com/courses/81978/assignments/465788"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part I -  Business Understanding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data set (which can be found at https://www.kaggle.com/fedesoriano/stroke-prediction-dataset) that we have chosen to utilize for this lab consists of data that may be used to identify whether or not an individual is at risk for strokes. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part II - Data Understanding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "print('Pandas:', pd.__version__)\n",
    "print('Numpy:',  np.__version__)\n",
    "\n",
    "df = pd.read_csv('healthcare-dataset-stroke-data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Quality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Formatting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To clean up the data a little bit, we're going to normalize the values of the non-numeric columns to have the same format by setting all values to lowercase and replacing spaces with underscores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in df.columns:\n",
    "    if df[c].dtype == 'object':\n",
    "        df[c] = df[c].str.lower()\n",
    "        \n",
    "df = df.replace(' ', '_', regex=True)\n",
    "        \n",
    "for c in df.columns:\n",
    "    if df[c].dtype == 'object':\n",
    "        print(df[c].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Duplicate Values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first thing we'll want to do to check the quality of the data is to check for duplicates. First, let's make sure there are no duplicate IDs in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if df.id.unique().size == df.id.size:\n",
    "    print(\"No duplicate IDs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we know there are no duplicate IDs, let's check if there are any rows with identical values (excluding the ID)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = df.columns.drop('id')\n",
    "\n",
    "s = df.duplicated(subset=cols, keep='first')\n",
    "\n",
    "s[s]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seems like the dataset has no exact duplicates. We feel safe assuming that, finding no exact duplicates, each entry in the dataset is unique."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Missing Values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second thing to check the dataset for is missing values. We can see them by checking df.info()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we see above, it seems that all of the columns except the bmi column have no missing values. However, lets check the non-numeric variables to see if any of their values could be considered \"missing\", even though a value is technically present."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for c in df.columns:\n",
    "    if df[c].dtype == 'object':\n",
    "        print(df[c].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All of the columns look good except for the smoking_status column. One of the values in that column is listed as 'unknown'. Though this is technically a value, what it is actually representing is missing information, so let's make that more clear."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.smoking_status.mask(df.smoking_status == 'unknown', np.nan, inplace=True)\n",
    "\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can see how much data is really missing from this dataset. We have over 1500 missing datapoints from the smoking_status column. Now let's take a look at both of the columns with missing data and see if we want to impute or delete them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.impute import KNNImputer\n",
    "import copy\n",
    "\n",
    "knn = KNNImputer(n_neighbors=3)\n",
    "\n",
    "temp = df[[\n",
    "    'age',\n",
    "    'hypertension',\n",
    "    'heart_disease',\n",
    "    'avg_glucose_level',\n",
    "    'bmi',\n",
    "    'stroke'\n",
    "]].to_numpy()\n",
    "\n",
    "temp_imputed = knn.fit_transform(temp)\n",
    "\n",
    "df_imputed = copy.deepcopy(df)\n",
    "df_imputed[[\n",
    "    'age',\n",
    "    'hypertension',\n",
    "    'heart_disease',\n",
    "    'avg_glucose_level',\n",
    "    'bmi',\n",
    "    'stroke'\n",
    "]] = temp_imputed\n",
    "# df_imputed.info()\n",
    "\n",
    "df_imputed.bmi = df_imputed.bmi.apply(lambda x: round(x, 1))\n",
    "\n",
    "print(df_imputed.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.simplefilter('ignore', DeprecationWarning)\n",
    "%matplotlib inline \n",
    "\n",
    "df_imputed.bmi.plot(kind='hist', alpha=0.5, label=\"imputed\",bins=100)\n",
    "df.bmi.plot(kind='hist', alpha=0.5, label=\"original\",bins=100)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()\n",
    "df.Residence_type.replace(to_replace= ['Urban', 'Rural'], value = range(1,3), inplace=True)\n",
    "df.work_type.replace(to_replace= ['Self-employed', 'Private',], value = range(1,3), inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part III - Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part IV - Exceptional Work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
