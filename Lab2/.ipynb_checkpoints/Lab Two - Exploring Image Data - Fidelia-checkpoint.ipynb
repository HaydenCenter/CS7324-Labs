{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab Two - Exploring Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You are to perform preprocessing and exploratory analysis of a data set: exploring the statistical summaries of the features, visualizing the attributes, and addressing data quality. This report is worth 10% of the final grade. Please upload a report (<b>one per team</b>) with all code used, visualizations, and text in a rendered Jupyter notebook. Any visualizations that cannot be embedded in the notebook, please provide screenshots of the output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Dataset requirements</b>: Choose a dataset that is comprised of image data. The data should be directories of images. That is, the dataset should not yet be pre-processed. The following are required for the dataset:\n",
    "\n",
    "<ol>\n",
    "    <li>The data includes at least 1000 images</li>\n",
    "    <li>The size of the images should be larger than 20x20 pixels</li>\n",
    "    <li>The dataset should have a well defined prediction task (i.e., a label for each image)</li>\n",
    "    <li>The dataset cannot be MNIST or Fashion MNIST</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i><b>A note on grading</b>: This lab is mostly about visualizing and understanding your dataset. The largest share of the points is from how you interpret the visuals that you make. Making the visuals is not enough to satisfy each of the rubrics belowâ€”you should appropriately explain what the implications of the visualizations are. In other words, expect about 20% of the available points for visuals that have no substantive discussion.</i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Business Understanding (2pts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ul>\n",
    "    <li><b>[2 points]</b> Give an overview of the dataset. Describe the purpose of the data set you selected (i.e., why was this data collected in the first place?). What is the prediction task for your dataset and which third parties would be interested in the results? Why is this data important? Once you begin modeling, how well would your prediction algorithm need to perform to be considered useful to the identified third parties? Be specific and use your own words to describe the aspects of the data.</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation (1pt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ul>\n",
    "    <li><b>[.5 points]</b> Read in your images as numpy arrays. Resize and recolor images as necessary.</li>\n",
    "    <li><b>[.4 points]</b> Linearize the images to create a table of 1-D image features (each row should be one image).</li>\n",
    "    <li><b>[.1 points]</b> Visualize several images.</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "#https://www.geeksforgeeks.org/how-to-convert-images-to-numpy-array/\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "#https://stackoverflow.com/questions/10377998/how-can-i-iterate-over-files-in-a-given-directory\n",
    "from pathlib import Path\n",
    "\n",
    "directory_in_str = './Coronahack-Chest-XRay-Dataset/train/'\n",
    "\n",
    "#array that will hold numpy arrays of images\n",
    "imagesToDisplay = []\n",
    "npImages = []\n",
    "linNpImages = []\n",
    "\n",
    "pathlist = list(Path(directory_in_str).rglob('*.jpeg'))\n",
    "pathlist.sort()\n",
    "for path in pathlist:\n",
    "    # because path is object not string\n",
    "    path_in_str = str(path)\n",
    "    \n",
    "    #https://auth0.com/blog/image-processing-in-python-with-pillow/\n",
    "    #convert to grayscale and resize image\n",
    "    image = Image.open(path_in_str).convert('LA')\n",
    "    resizedImage = image.resize((100,100))\n",
    "    imagesToDisplay.append(resizedImage)\n",
    "    \n",
    "    #convert to numpy array\n",
    "    numpyImage = np.asarray(resizedImage)\n",
    "    npImages.append(numpyImage)\n",
    "    numpyImage = numpyImage[:,:,0]\n",
    "    \n",
    "    #linearize data\n",
    "    linNumpyImage = numpyImage.flatten().reshape(1,10000)\n",
    "    linNpImages.append(linNumpyImage)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = pd.read_csv('./Chest_xray_Corona_Metadata.csv')\n",
    "classifications = summary.Label.to_numpy()\n",
    "\n",
    "summary['Label'] = summary.Label\n",
    "summary[summary.Label=='Pneumonia'] = 'Pneumonia'\n",
    "summary[summary.Label=='Normal'] = 'Normal'\n",
    "labels = summary.Label.to_numpy()\n",
    "\n",
    "def plot_gallery(images, titles, h, w, n_row=3, n_col=3):\n",
    "    \"\"\"Helper function to plot a gallery of portraits\"\"\"\n",
    "    plt.figure(figsize=(n_col * n_col, 6 * n_row))\n",
    "    plt.subplots_adjust(bottom=0, left=.01, right=.99, top=.90, hspace=.35)\n",
    "    for i in range(n_row * n_col):\n",
    "        plt.subplot(n_row * 2, n_col, i + 1)\n",
    "        plt.imshow(imagesToDisplay[i], cmap=plt.cm.gray)\n",
    "        plt.title(titles[i], size=12)\n",
    "        plt.xticks(())\n",
    "        plt.yticks(())\n",
    "    for j in range(n_row * n_col):\n",
    "        plt.subplot(n_row * 2, n_col, n_row * n_col + j + 1)\n",
    "        plt.imshow(imagesToDisplay[-1*j], cmap=plt.cm.gray)\n",
    "        plt.title(titles[-1*j], size=12)\n",
    "        plt.xticks(())\n",
    "        plt.yticks(())\n",
    "        \n",
    "plot_gallery(imagesToDisplay, labels, 100, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Reduction (6pts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ul>\n",
    "    <li><b>[.5 points]</b> Perform linear dimensionality reduction of the images using principal components analysis. Visualize the explained variance of each component. Analyze how many dimensions are required to adequately represent your image data. Explain your analysis and conclusion.\n",
    "    <li><b>[.5 points]</b> Perform linear dimensionality reduction of your image data using randomized principle components analysis. Visualize the explained variance of each component. Analyze how many dimensions are required to adequately represent your image data. Explain your analysis and conclusion.</li>\n",
    "    <li><b>[2 points]</b>  Compare the representation using PCA and Randomized PCA. The method you choose to compare dimensionality methods should quantitatively explain which method is better at representing the images with fewer components.  Do you prefer one method over another? Why?</li>\n",
    "    <li><b>[1 points]</b> Perform feature extraction upon the images using any feature extraction technique (e.g., gabor filters, ordered gradients, DAISY, etc.).</li>\n",
    "    <li><b>[2 points]</b> Does this feature extraction method show promise for your prediction task? Why? Use visualizations to analyze this questions. For example, visualize the differences between statistics of extracted features in each target class. Another option, use a heat map of the pairwise differences (ordered by class) among all extracted features. Another option, build a nearest neighbor classifier to see actual classification performance.</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<li><b>[.5 points]</b> Perform linear dimensionality reduction of the images using principal components analysis. Visualize the explained variance of each component. Analyze how many dimensions are required to adequately represent your image data. Explain your analysis and conclusion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# manipulated from Sebastian Raschka Example (your book!)\n",
    "# also from hi blog here: http://sebastianraschka.com/Articles/2015_pca_in_3_steps.html\n",
    "\n",
    "def plot_explained_variance(pca):\n",
    "    import plotly\n",
    "    from plotly.graph_objs import Bar, Line\n",
    "    from plotly.graph_objs import Scatter, Layout\n",
    "    from plotly.graph_objs.scatter import Marker\n",
    "    from plotly.graph_objs.layout import XAxis, YAxis\n",
    "    plotly.offline.init_notebook_mode() # run at the start of every notebook\n",
    "    \n",
    "    explained_var = pca.explained_variance_ratio_\n",
    "    cum_var_exp = np.cumsum(explained_var)\n",
    "    \n",
    "    plotly.offline.iplot({\n",
    "        \"data\": [Bar(y=explained_var, name='individual explained variance'),\n",
    "                 Scatter(y=cum_var_exp, name='cumulative explained variance')\n",
    "            ],\n",
    "        \"layout\": Layout(xaxis=XAxis(title='Principal components'), yaxis=YAxis(title='Explained variance ratio'))\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = linNpImages\n",
    "X = [np.concatenate(i) for i in X]\n",
    "\n",
    "# specify height and width\n",
    "h, w = (100,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "n_components = 300\n",
    "\n",
    "pca = PCA(n_components=n_components)\n",
    "pca.fit(X.copy())\n",
    "eigenlungs_pca = pca.components_.reshape((n_components, h, w))\n",
    "plot_explained_variance(pca)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analyzing the explained variance graph for each component, we can see that to represent an image with 80% accuracy, it takes 30 components and 90% accuracy takes about 117 components. We can adequately represent our image with 80% accuracy because there is a fewer amount of components required to create a fairly accurate image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eigenlung_titles = [\"eigenlung %d\" % i for i in range(eigenlungs_pca.shape[0])]\n",
    "plot_gallery(eigenlungs_pca, eigenlung_titles, h, w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reconstruct_image(trans_obj,org_features):\n",
    "    low_rep = trans_obj.transform(org_features)\n",
    "    rec_image = trans_obj.inverse_transform(low_rep)\n",
    "    return low_rep, rec_image\n",
    "    \n",
    "idx_to_reconstruct = 1    \n",
    "X_idx = X[idx_to_reconstruct]\n",
    "low_dimensional_representation, reconstructed_image = reconstruct_image(pca,X_idx.reshape(1, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplot(1,2,1)\n",
    "plt.imshow(X_idx.reshape((h, w)), cmap=plt.cm.gray)\n",
    "plt.title('Original')\n",
    "plt.grid(False)\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(reconstructed_image.reshape((h, w)), cmap=plt.cm.gray)\n",
    "plt.title('Reconstructed from Full PCA')\n",
    "plt.grid(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## honestly i dont know what the fuck this means rn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <li><b>[.5 points]</b> Perform linear dimensionality reduction of your image data using randomized principle components analysis. Visualize the explained variance of each component. Analyze how many dimensions are required to adequately represent your image data. Explain your analysis and conclusion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets do some PCA of the features and go from 1850 features to 300 features\n",
    "\n",
    "n_components = 300\n",
    "rpca = PCA(n_components=n_components, svd_solver='randomized')\n",
    "%time rpca.fit(X.copy())\n",
    "eigenlungs = rpca.components_.reshape((n_components, h, w))\n",
    "plot_explained_variance(rpca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eigenlung_titles = [\"eigenlung %d\" % i for i in range(eigenlungs.shape[0])]\n",
    "plot_gallery(eigenlungs, eigenlung_titles, h, w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_to_reconstruct = 1    \n",
    "X_idx = X[idx_to_reconstruct]\n",
    "low_dimensional_representation, reconstructed_image = reconstruct_image(pca,X_idx.reshape(1, -1))\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(X_idx.reshape((h, w)), cmap=plt.cm.gray)\n",
    "plt.title('Original')\n",
    "plt.grid(False)\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(reconstructed_image.reshape((h, w)), cmap=plt.cm.gray)\n",
    "plt.title('Reconstructed from Randomized PCA')\n",
    "plt.grid(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exceptional Work (1pt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ul>\n",
    "    <li>One idea (<b>required for 7000 level students</b>): Perform feature extraction upon the images using DAISY. Rather than using matching go the images with the total DAISY vector, you will instead use key point matching. You will need to investigate appropriate methods for key point matching using DAISY. NOTE: this often requires some type of brute force matching per pair of images, which can be computationally expensive.</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
