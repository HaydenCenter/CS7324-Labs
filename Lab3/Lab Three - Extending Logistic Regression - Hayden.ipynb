{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab Three - Extending Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lab, you will compare the performance of logistic regression optimization programmed in scikit-learn and via your own implementation. You will also modify the optimization procedure for logistic regression. \n",
    "\n",
    "This report is worth 10% of the final grade. Please upload a report (<b>one per team</b>) with all code used, visualizations, and text in a rendered Jupyter notebook. Any visualizations that cannot be embedded in the notebook, please provide screenshots of the output. The results should be reproducible using your report. Please carefully describe every assumption and every step in your report."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Dataset Selection</b>\n",
    "\n",
    "Select a dataset identically to the way you selected for the lab one (i.e., table data). You are not required to use the same dataset that you used in the past, but you are encouraged. You must identify a classification task from the dataset that contains <b>three or more classes to predict</b>. That is it cannot be a binary classification; it must be multi-class prediction. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparation and Overview (3pt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ul>\n",
    "    <li>[<b>2 points</b>] Explain the task and what business-case or use-case it is designed to solve (or designed to investigate). Detail exactly what the classification task is and what parties would be interested in the results. For example, would the model be deployed or used mostly for offline analysis? </li>\n",
    "    <li>[<b>.5 points</b>] (<i>mostly the same processes as from previous labs</i>) Define and prepare your class variables. Use proper variable representations (int, float, one-hot, etc.). Use pre-processing methods (as needed) for dimensionality reduction, scaling, etc. Remove variables that are not needed/useful for the analysis. Describe the final dataset that is used for classification/regression (include a description of any newly formed variables you created). </li>\n",
    "    <li>[<b>.5 points</b>] Divide you data into training and testing data using an 80% training and 20% testing split. Use the cross validation modules that are part of scikit-learn. <b>Argue \"for\" or \"against\" splitting your data using an 80/20 split. That is, why is the 80/20 split appropriate (or not) for your dataset?</b></li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use Case\n",
    "\n",
    "Our task will be looking at a patients information and determining whether they are likely to have a stroke, heart disease, or hypertension. The use-case for this classifier would be to flag at-risk patients and enable some kind of response to be made to prevent serious medical emergencies that these conditions might cause or prevent the conditions in the first place.\n",
    "\n",
    "For example, if a person were to be flagged as very likely to have a stroke, the doctor could contact the patient in an attempt to prevent the stroke by prescribing them medication or alerting the patient's family to monitor them in case they were to have a stroke. Similar actions could be taken for hypertension and heart disease.\n",
    "\n",
    "Alernatively, some kind of application could be made to allow people to enter their information and determine how at risk they might be for these conditions, giving people more clear information about their health and the issues that are likely to affect them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing packages and reading in dataset\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "print('Pandas:', pd.__version__)\n",
    "print('Numpy:',  np.__version__)\n",
    "\n",
    "raw_data = pd.read_csv('healthcare-dataset-stroke-data.csv')\n",
    "raw_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Dropping categorical column 'work_type'; not very useful and\n",
    "# doesn't translate nicely into ordinal numbers\n",
    "df = raw_data.drop('work_type', axis = 1)\n",
    "\n",
    "# Dropping 1 observation of person with gender 'Other' to simplify\n",
    "# using the gender column to calculate, impute, or visualize\n",
    "df.drop(df[df.gender == 'Other'].index, inplace=True)\n",
    "\n",
    "# Making values' format consistent\n",
    "for c in df.columns:\n",
    "    if df[c].dtype == 'object':\n",
    "        df[c] = df[c].str.lower()\n",
    "\n",
    "# Adding numbers to smoking_status values to order them properly\n",
    "# when they will get passed through the SKLearn LabelEncoder\n",
    "df.smoking_status.replace(to_replace= ['never smoked', 'formerly smoked', 'smokes', 'Unknown'],\n",
    "                          value     = ['0_never_smoked', '1_formerly_smoked', '2_smokes', '3_Unknown'],\n",
    "                          inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Encoding all of the non-numeric columns\n",
    "le = {}\n",
    "\n",
    "for col in df.columns:\n",
    "    if df[col].dtype == 'object':\n",
    "        le[col] = LabelEncoder()\n",
    "        df[col] = le[col].fit_transform(df[col])\n",
    "\n",
    "# Call le[col].inverse_transform(df[col]) for any column name\n",
    "# to convert numbers back to their labels\n",
    "\n",
    "# Converting all 'Unknown' values in smoking status to NaN so\n",
    "# that we can impute the missing values.\n",
    "df.smoking_status.mask(df.smoking_status == 3, np.nan, inplace=True)\n",
    "               \n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Imputing missing values\n",
    "from sklearn.impute import KNNImputer\n",
    "import copy\n",
    "\n",
    "knn = KNNImputer(n_neighbors=3)\n",
    "\n",
    "# Imputing on all columns except id\n",
    "columns = list(df.columns)\n",
    "columns.remove('id')\n",
    "\n",
    "df_imputed = copy.deepcopy(df)\n",
    "df_imputed[columns] = knn.fit_transform(df[columns])\n",
    "\n",
    "# Rounding imputed values to be compatible with LabelEncoder\n",
    "# for smoking_status and to match the format of other values\n",
    "# for bmi\n",
    "df_imputed.smoking_status = df_imputed.smoking_status.apply(lambda x: round(x, 0))\n",
    "df_imputed.bmi = df_imputed.bmi.apply(lambda x: round(x, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Using df_imputed as the primary dataset\n",
    "df = df_imputed\n",
    "\n",
    "# Changing columns modified by KNN Imputer back to integers from floats\n",
    "columns = [\n",
    "    'gender',\n",
    "    'hypertension',\n",
    "    'heart_disease',\n",
    "    'ever_married',\n",
    "    'residence_type',\n",
    "    'smoking_status',\n",
    "    'stroke'\n",
    "]\n",
    "\n",
    "for col in columns:\n",
    "    df[col] = df[col].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To prep this dataset, one attribute was removed due to it being relatively unimportant and not encoding nicely into an ordinal set of integers. All categorical variables were converted to numeric data using SKLearn's LabelEncoder class. Missing values for bmi and smoking_status were imputed using KNN Imputer. One record was dropped for being the only entry with gender 'Other'. Removing this record will make visualizing the gender data simpler and will have little impact on the training, as having an outlier like that might cause other attributes to be slightly undervalued in comparison."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is a table of the LabelEncoder encoded variables.\n",
    "\n",
    "| value | gender | ever_married | residence_type | smoking_status    |\n",
    "|-------|--------|--------------|----------------|-------------------|\n",
    "| 0     | female | no           | rural          | 0_never_smoked    |\n",
    "| 1     | male   | yes          | urban          | 1_formerly_smoked |\n",
    "| 2     |   -    |      -       |       -        | 2_smokes          |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Division"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# THIS IS NOT FINAL, LOOKING INTO CROSS VALIDATION AS METHOD\n",
    "\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "columns = list(df.columns).remove('id')\n",
    "\n",
    "clf = SKLogisticRegression(solver='liblinear')\n",
    "scores = cross_validate(clf, X, y, scoring=scoring)\n",
    "sorted(scores.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling (5pt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ul>\n",
    "    <li>The implementation of logistic regression must be written only from the examples given to you by the instructor. No credit will be assigned to teams that copy implementations from another source, regardless of if the code is properly cited.</li>\n",
    "    <li>[<b>2 points</b>] Create a custom, one-versus-all logistic regression classifier using numpy and scipy to optimize. Use object oriented conventions identical to scikit-learn. You should start with the template developed by the instructor in the course. You should add the following functionality to the logistic regression classifier:\n",
    "    <ul>\n",
    "        <li>Ability to choose optimization technique when class is instantiated: either steepest descent, stochastic gradient descent, or Newton's method. </li>\n",
    "        <li>Update the gradient calculation to include a customizable regularization term (either using no regularization, L1 regularization, L2 regularization, or both L1 and L2 regularization). Associate a cost with the regularization term, \"C\", that can be adjusted when the class is instantiated.  </li>\n",
    "    </ul>\n",
    "    </li>\n",
    "    <li>[<b>1.5 points</b>] Train your classifier to achieve good generalization performance. That is, adjust the <b>optimization technique</b> and the value of the <b>regularization term \"C\"</b> to achieve the best performance on your test set. Visualize the performance of the classifier versus the parameters you investigated. Is your method of selecting parameters justified? That is, do you think there is any \"data snooping\" involved with this method of selecting parameters?</li>\n",
    "    <li>[<b>1.5 points</b>] Compare the performance of your \"best\" logistic regression optimization procedure to the procedure used in scikit-learn. Visualize the performance differences in terms of training time and classification performance. <b>Discuss the results</b>. </li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deployment (1pt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ul>\n",
    "    <li>Which implementation of logistic regression would you advise be used in a deployed machine learning model, your implementation or scikit-learn (or other third party)? Why?</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exceptional Work (1pt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ul>\n",
    "    <li>You have free reign to provide additional analyses. <b>One idea</b>: Update the code to use either \"one-versus-all\" or \"one-versus-one\" extensions of binary to multi-class classification. </li>\n",
    "    <li><b>Required for 7000 level students</b>: Choose ONE of the following:\n",
    "    <ul>\n",
    "        <li><b>Option One</b>: Implement an optimization technique for logistic regression using <b>mean square error</b> as your objective function (instead of binary cross entropy). Derive the gradient updates for the Hessian and use Newton's method to update the values of \"w\". Then answer, is this process better than using binary cross entropy? </li>\n",
    "        <li><b>Option Two</b>: Implement the BFGS algorithm from scratch to optimize logistic regression. That is, use BFGS without the use of an external package (for example, do not use SciPy). Compare your performance accuracy and runtime to the BFGS implementation in SciPy (that we used in lecture). </li>\n",
    "    </ul>\n",
    "    </li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
