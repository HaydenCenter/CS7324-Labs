{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab Three - The Multi-Layer Perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lab, you will compare the performance of multi-layer perceptrons programmed  via your own various implementations. <br>\n",
    "\n",
    "This report is worth 10% of the final grade. Please upload a report (<b>one per team</b>) with all code used, visualizations, and text in a rendered Jupyter notebook. Any visualizations that cannot be embedded in the notebook, please provide screenshots of the output. The results should be reproducible using your report. This lab project is slightly different from other reports in that you will be asked to complete more specific items.\n",
    "\n",
    "<b>Dataset Selection</b>\n",
    "\n",
    "For this assignment, you will be using a specific dataset chosen by the instructor.  This is US Census data available on Kaggle, and also downloadable from the following link: https://www.dropbox.com/s/bf7i7qjftk7cmzq/acs2017_census_tract_data.csv?dl=0 (Links to an external site.)\n",
    "\n",
    "The Kaggle description appears here: https://www.kaggle.com/muonneutrino/us-census-demographic-data/data (Links to an external site.) \n",
    "\n",
    "The classification task you will be performing is to predict, for each county, what the child poverty rate will be. You will need to convert this from regression to <b>four levels of classification</b> by quantizing the variable of interest. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reminder of Assignments:\n",
    "<ul>\n",
    "    <li>Hayden</li>\n",
    "    <ul>\n",
    "        <li>Load, Split, and Balance</li>\n",
    "        <li>Pre-processing</li>\n",
    "    </ul>\n",
    "    <li>Amory</li>\n",
    "    <ul>\n",
    "        <li>Load, Split, and Balance</li>\n",
    "    </ul>\n",
    "    <li>Fidelia</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load, Split, and Balance (1.5 pts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ul>\n",
    "    <li>[<b>.5 points</b>] Load the data into memory and save it to a pandas data frame. Do not normalize or one-hot encode any of the variables until asked to do so.  Remove any observations that having missing data. Encode any string data as integers for now. </li>\n",
    "    <li>[<b>.5 points</b>] Assume you are equally interested in the classification performance for each class in the dataset. Split the dataset into 80% for training and 20% for testing.</li>\n",
    "    <li>[<b>.5 points</b>] Balance the dataset so that about the same number of instances are within each class. Choose a method for balancing the dataset and explain your reasoning for selecting this method. One option is to choose quantization thresholds for the \"ChildPoverty\" variable that equally divide the data into four classes. <i>Should balancing of the dataset be done for both the training and testing set? Explain.</i></li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-processing (2.5 pts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ul>\n",
    "    <li>There are a number of version of the two layer perceptron covered in class. When using the example two layer network from class be sure that you use: (1) vectorized computation, (2) mini-batching, and (3) proper Glorot initialization, at a minimum.  </li>\n",
    "    <li>[<b>.5 points</b>] Use the example two-layer perceptron network from the class example and quantify performance using accuracy. Do not normalize or one-hot encode the data (not yet). Be sure that training converges by graphing the loss function versus the number of epochs. </li>\n",
    "    <li>[<b>.5 points</b>] Now normalize the continuous numeric feature data. Use the example two-layer perceptron network from the class example and quantify performance using accuracy. Be sure that training converges by graphing the loss function versus the number of epochs.  </li>\n",
    "    <li>[<b>.5 points</b>] Now normalize the continuous numeric feature data AND one hot encode the categorical data. Use the example two-layer perceptron network from the class example and quantify performance using accuracy. Be sure that training converges by graphing the loss function versus the number of epochs. </li>\n",
    "    <li>[<b>1 points</b>] Compare the performance of the three models you just trained. Are there any meaningful differences in performance? Explain, in your own words, why these models have (or do not have) different performances.</li>  \n",
    "        <ul>\n",
    "            <li><i>Use one-hot encoding and normalization on the dataset for the remainder of this lab assignment.</i></li>\n",
    "        </ul>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling (5 pts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ul>\n",
    "    <li>[<b>1 points</b>] Add support for a third layer in the multi-layer perceptron. Add support for saving (and plotting after training is completed) the average magnitude of the gradient for each layer, for each epoch. For magnitude calculation, you are free to use either the average absolute values or the L1/L2 norm. Quantify the performance of the model and graph the magnitudes for each layer versus the number of epochs.</li>\n",
    "    <li>[<b>1 points</b>] Repeat the previous step, adding support for a fourth layer.</li>\n",
    "    <li>[<b>1 points</b>] Repeat the previous step, adding support for a fifth layer. </li>\n",
    "    <li>[<b>2 points</b>] Implement an adaptive learning technique that was discussed in lecture and use it on the five layer network. Compare the performance of this model with and without the adaptive learning strategy. Do not use AdaM for the adaptive learning technique. </li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exceptional Work (1 pts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ul>\n",
    "    <li>5000 level student: You have free reign to provide additional analyses.</li>\n",
    "    <li>One idea (<b>required for 7000 level students</b>):  Implement adaptive momentum (AdaM) in the five layer neural network and quantify the performance. </li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
