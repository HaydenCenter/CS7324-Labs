{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab Five: Wide and Deep Network Architectures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lab, you will select a prediction task to perform on your dataset, evaluate two different deep learning architectures and tune hyper-parameters for each architecture. If any part of the assignment is not clear, ask the instructor to clarify. \n",
    "\n",
    "This report is worth 10% of the final grade. Please upload a report (<b>one per team</b>) with all code used, visualizations, and text in a rendered Jupyter notebook. Any visualizations that cannot be embedded in the notebook, please provide screenshots of the output. The results should be reproducible using your report. Please carefully describe every assumption and every step in your report.\n",
    "\n",
    "<b>Dataset Selection</b>\n",
    "\n",
    "Select a dataset similarly to lab one. That is, the dataset must be table data. In terms of generalization performance, it is helpful to have a large dataset for building a wide and deep network. It is also helpful to have many different categorical features to create the embeddings and cross-product embeddings. It is fine to perform binary classification, multi-class classification, or regression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparation (4 pts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ul>\n",
    "    <li>[<b>1 points</b>] Define and prepare your class variables. Use proper variable representations (int, float, one-hot, etc.). Use pre-processing methods (as needed) for dimensionality reduction, scaling, etc. Remove variables that are not needed/useful for the analysis. Describe the final dataset that is used for classification/regression (include a description of any newly formed variables you created). \n",
    "    <li>[<b>1 points</b>] Identify groups of features in your data that should be combined into cross-product features. Provide justification for why these features should be crossed (or why some features should not be crossed).</li>\n",
    "    <li>[<b>1 points</b>] Choose and explain what metric(s) you will use to evaluate your algorithmâ€™s performance. You should give a <b>detailed argument for why this (these) metric(s) are appropriate on your data</b>. That is, why is the metric appropriate for the task (e.g., in terms of the business case for the task). Please note: rarely is accuracy the best evaluation metric to use. Think deeply about an appropriate measure of performance.</li>\n",
    "    <li>[<b>1 points</b>] Choose the method you will use for dividing your data into training and testing (i.e., are you using Stratified 10-fold cross validation? Shuffle splits? Why?). <b>Explain why your chosen method is appropriate or use more than one method as appropriate</b>. Argue why your cross validation method is a realistic mirroring of how an algorithm would be used in practice. </li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pandas: 1.1.0\n",
      "Numpy: 1.20.1\n"
     ]
    }
   ],
   "source": [
    "# Importing packages and reading in dataset\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "print('Pandas:', pd.__version__)\n",
    "print('Numpy:',  np.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 13119 entries, 1413 to 11207\n",
      "Data columns (total 9 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   model         13119 non-null  object \n",
      " 1   year          13119 non-null  int64  \n",
      " 2   price         13119 non-null  int64  \n",
      " 3   transmission  13119 non-null  object \n",
      " 4   mileage       13119 non-null  int64  \n",
      " 5   fuelType      13119 non-null  object \n",
      " 6   tax           13119 non-null  int64  \n",
      " 7   mpg           13119 non-null  float64\n",
      " 8   engineSize    13119 non-null  float64\n",
      "dtypes: float64(2), int64(4), object(3)\n",
      "memory usage: 1.0+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#read in csv file\n",
    "merc_info = pd.read_csv('merc.csv')\n",
    "\n",
    "#shuffle data\n",
    "merc_info = merc_info.sample(frac=1)\n",
    "\n",
    "#no null values, therefore do not need to impute any data\n",
    "print(merc_info.info(null_counts=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 13119 entries, 1413 to 11207\n",
      "Data columns (total 12 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   model             13119 non-null  object \n",
      " 1   year              13119 non-null  float64\n",
      " 2   transmission      13119 non-null  object \n",
      " 3   fuelType          13119 non-null  object \n",
      " 4   tax               13119 non-null  float64\n",
      " 5   mpg               13119 non-null  float64\n",
      " 6   engineSize        13119 non-null  float64\n",
      " 7   log_price         13119 non-null  float64\n",
      " 8   log_mileage       13119 non-null  float64\n",
      " 9   model_int         13119 non-null  int64  \n",
      " 10  transmission_int  13119 non-null  int64  \n",
      " 11  fuelType_int      13119 non-null  int64  \n",
      "dtypes: float64(6), int64(3), object(3)\n",
      "memory usage: 1.3+ MB\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-3-fd01a65de750>:24: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  merc_info[num] = merc_info[num].astype(np.float)\n",
      "<ipython-input-3-fd01a65de750>:24: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  merc_info[num] = merc_info[num].astype(np.float)\n",
      "<ipython-input-3-fd01a65de750>:24: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  merc_info[num] = merc_info[num].astype(np.float)\n",
      "<ipython-input-3-fd01a65de750>:24: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  merc_info[num] = merc_info[num].astype(np.float)\n",
      "<ipython-input-3-fd01a65de750>:24: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  merc_info[num] = merc_info[num].astype(np.float)\n",
      "<ipython-input-3-fd01a65de750>:24: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  merc_info[num] = merc_info[num].astype(np.float)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "merc_info[\"log_price\"] = np.log(merc_info[\"price\"])\n",
    "del merc_info[\"price\"]\n",
    "\n",
    "merc_info[\"log_mileage\"] = np.log(merc_info[\"mileage\"])\n",
    "del merc_info[\"mileage\"]\n",
    "\n",
    "# define objects that can encode each variable as integer\n",
    "categorical = [\"model\", \"transmission\", \"fuelType\"]\n",
    "encoders = dict()\n",
    "\n",
    "# train all encoders\n",
    "for cat in categorical:\n",
    "    # integer encoded variables\n",
    "    encoders[cat] = LabelEncoder() # save the encoder\n",
    "    merc_info[cat+'_int'] = encoders[cat].fit_transform(merc_info[cat])\n",
    "\n",
    "# scale the numeric, continuous variables\n",
    "numerical = [\"year\", \"log_price\", \"log_mileage\", \"tax\", \"mpg\", \"engineSize\"]\n",
    "\n",
    "for num in numerical:\n",
    "    merc_info[num] = merc_info[num].astype(np.float)\n",
    "    ss = StandardScaler()\n",
    "    merc_info[num] = ss.fit_transform(merc_info[num].values.reshape(-1, 1))\n",
    "    \n",
    "categorical_headers_ints = [x+'_int' for x in categorical]\n",
    "feature_columns = categorical_headers_ints + numerical\n",
    "\n",
    "# Define features and target\n",
    "X = merc_info[feature_columns]\n",
    "y = merc_info[\"log_price\"]\n",
    "\n",
    "print(merc_info.info(null_counts=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       model_int  transmission_int  fuelType_int      year  log_price  \\\n",
      "1413          21                 3             0 -1.032214   0.333275   \n",
      "12525         11                 0             3  0.765843   0.145769   \n",
      "8123           2                 3             3  0.765843  -0.290833   \n",
      "9014          21                 3             0  0.316329   1.105907   \n",
      "9273           0                 1             3  0.765843   0.002002   \n",
      "...          ...               ...           ...       ...        ...   \n",
      "7357          13                 3             0  0.765843   0.803197   \n",
      "1829           2                 3             0 -0.133186  -0.708933   \n",
      "4341           0                 3             3 -0.582700  -0.211582   \n",
      "2065           0                 3             3  0.316329   0.243733   \n",
      "11207         10                 0             3  0.316329  -0.188863   \n",
      "\n",
      "       log_mileage       tax       mpg  engineSize  \n",
      "1413      1.055699  1.609429 -0.680432    0.224440  \n",
      "12525    -0.507785  0.230284 -1.245497   -0.823771  \n",
      "8123      0.149760  0.230284 -0.581875   -0.998472  \n",
      "9014     -0.948506  0.230284 -0.680432    0.224440  \n",
      "9273     -2.533870  0.230284 -0.627868   -1.347876  \n",
      "...            ...       ...       ...         ...  \n",
      "7357     -0.102620  0.230284 -0.897259    0.049738  \n",
      "1829      0.133720  0.230284  0.594248    0.049738  \n",
      "4341     -0.099668  1.073095 -0.811843   -0.124964  \n",
      "2065     -0.519665  0.230284 -0.121938   -1.347876  \n",
      "11207     0.153562  0.230284 -0.312483   -0.823771  \n",
      "\n",
      "[13119 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "print(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling (5 pts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ul>\n",
    "    <li>[<b>2 points</b>] Create at least three combined wide and deep networks to classify your data using Keras. Visualize the performance of the network on the training data and validation data in the same plot versus the training iterations. Note: use the \"history\" return parameter that is part of Keras \"fit\" function to easily access this data. </li> \n",
    "    <li>[<b>2 points</b>] Investigate generalization performance by altering the number of layers in the deep branch of the network. Try at least two different number of layers. Use the method of cross validation and evaluation metric that you argued for at the beginning of the lab to select the number of layers that performs superiorly. </li>\n",
    "    <li>[<b>1 points</b>] Compare the performance of your best wide and deep network to a standard multi-layer perceptron (MLP). For classification tasks, use the receiver operating characteristic and area under the curve. For regression tasks, use Bland-Altman plots and residual variance calculations.  Use proper statistical method to compare the performance of different models.  </li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exceptional Work (1 pt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ul>\n",
    "    <li> 5000 students: You have free reign to provide additional analyses. </li> \n",
    "    <li>One idea (<b>required for 7000 level students</b>): Capture the embedding weights from the deep network and (<b>if needed</b>) perform dimensionality reduction on the output of these embedding layers (<b>only if needed</b>). That is, pass the observations into the network, save the embedded weights (called embeddings), and then perform  dimensionality reduction in order to visualize results. Visualize and explain any clusters in the data. </li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
