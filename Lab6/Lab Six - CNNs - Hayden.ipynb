{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab Six -  Convolutional Network Architectures\n",
    "Amory Weinzierl, Fidelia Nawar, and Hayden Center"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lab, you will select a prediction task to perform on your dataset, evaluate a deep learning architecture and tune hyper-parameters. If any part of the assignment is not clear, ask the instructor to clarify. \n",
    "\n",
    "This report is worth 10% of the final grade. Please upload a report (<b>one per team</b>) with all code used, visualizations, and text in a rendered Jupyter notebook. Any visualizations that cannot be embedded in the notebook, please provide screenshots of the output. The results should be reproducible using your report. Please carefully describe every assumption and every step in your report.\n",
    "\n",
    "<b>Dataset Selection</b>\n",
    "\n",
    "Select a dataset identically to lab two (images). That is, the dataset must be image data. In terms of generalization performance, it is helpful to have a large dataset of identically sized images. It is fine to perform binary classification or multi-class classification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparation (3 pts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [<b>1.5 points</b>] Choose and explain what metric(s) you will use to evaluate your algorithmâ€™s performance. You should give a <b>detailed argument for why this (these) metric(s) are appropriate on your data. That is, why is the metric appropriate</b>b for the task (e.g., in terms of the business case for the task). Please note: rarely is accuracy the best evaluation metric to use. Think deeply about an appropriate measure of performance.\n",
    "- [<b>1.5 points</b>] Choose the method you will use for dividing your data into training and testing (i.e., are you using Stratified 10-fold cross validation? Shuffle splits? Why?). <b>Explain why your chosen method is appropriate or use more than one method as appropriate</b>. Convince me that your cross validation method is a realistic mirroring of how an algorithm would be used in practice. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pandas: 1.2.1\n",
      "Numpy: 1.19.2\n"
     ]
    }
   ],
   "source": [
    "# Importing packages and reading in dataset\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "print('Pandas:', pd.__version__)\n",
    "print('Numpy:',  np.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './Coronahack-Chest-XRay-Dataset/train/IM-0128-0001.jpeg'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-390493ee181f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mimg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtrain_images\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 32\u001b[1;33m     \u001b[0mimg_arr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mImage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_path\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'L'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mh\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     33\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m     \u001b[1;31m# Image data in correct dimensions (100 x 100)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\mlenv2020\\lib\\site-packages\\PIL\\Image.py\u001b[0m in \u001b[0;36mopen\u001b[1;34m(fp, mode, formats)\u001b[0m\n\u001b[0;32m   2902\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2903\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfilename\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2904\u001b[1;33m         \u001b[0mfp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"rb\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2905\u001b[0m         \u001b[0mexclusive_fp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2906\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './Coronahack-Chest-XRay-Dataset/train/IM-0128-0001.jpeg'"
     ]
    }
   ],
   "source": [
    "#source: https://www.geeksforgeeks.org/how-to-convert-images-to-numpy-array/\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "#source: https://stackoverflow.com/questions/10377998/how-can-i-iterate-over-files-in-a-given-directory\n",
    "from pathlib import Path\n",
    "\n",
    "#directory name\n",
    "train_path = './Coronahack-Chest-XRay-Dataset/train/'\n",
    "test_path = './Coronahack-Chest-XRay-Dataset/test/'\n",
    "\n",
    "metadata = pd.read_csv('./Chest_xray_Corona_Metadata.csv')\n",
    "\n",
    "image_data_train = metadata[metadata['Dataset_type'] != \"TEST\"]\n",
    "image_data_target = metadata[metadata['Dataset_type'] == \"TEST\"]\n",
    "\n",
    "labels = list(metadata.Label)\n",
    "\n",
    "%time\n",
    "\n",
    "train_images = image_data_train['X_ray_image_name'].copy(deep=True)\n",
    "target_images = image_data_target['X_ray_image_name'].copy(deep=True)\n",
    "\n",
    "imagesToDisplay = []\n",
    "X = []\n",
    "y = []\n",
    "h, w = 100, 100\n",
    "\n",
    "for img in train_images:\n",
    "    \n",
    "    img_arr = np.asarray(Image.open(train_path + img).convert('L').resize((h,w)))\n",
    "    \n",
    "    # Image data in correct dimensions (100 x 100)\n",
    "    imagesToDisplay.append(img_arr)\n",
    "    \n",
    "    X.append(img_arr)\n",
    "\n",
    "for img in target_images:\n",
    "    img_arr = np.asarray(Image.open(test_path + img).convert('L').resize((h,w)))\n",
    "    y.append(img_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(X).astype(np.float32)/16.0 - 0.5\n",
    "y = np.array(y).astype(np.int32)\n",
    "\n",
    "print(X.shape, type(X))\n",
    "print(y.shape, type(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot images\n",
    "def plot_gallery(images, titles, h, w, n_row=3, n_col=3):\n",
    "    \"\"\"Helper function to plot a gallery of portraits\"\"\"\n",
    "    plt.figure(figsize=(n_col * n_col, 6 * n_row))\n",
    "    plt.subplots_adjust(bottom=0, left=.01, right=.99, top=.90, hspace=.35)\n",
    "    #normal scans tended towards front\n",
    "    for i in range(n_row * n_col):\n",
    "        plt.subplot(n_row * 2, n_col, i + 1)\n",
    "        plt.imshow(images[i], cmap=plt.cm.gray)\n",
    "        plt.title(titles[i], size=12)\n",
    "        plt.xticks(())\n",
    "        plt.yticks(())\n",
    "    #pnemonia scans toward back so we pulled some from the back \n",
    "    #for demonstration purposes\n",
    "    for j in range(n_row * n_col):\n",
    "        plt.subplot(n_row * 2, n_col, n_row * n_col + j + 1)\n",
    "        plt.imshow(images[-1*j], cmap=plt.cm.gray)\n",
    "        plt.title(titles[-1*j], size=12)\n",
    "        plt.xticks(())\n",
    "        plt.yticks(())\n",
    "        \n",
    "plot_gallery(imagesToDisplay, labels, 100, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation Metric\n",
    "\n",
    "The evaluation metric we are using for our model is recall. This metric is the ratio of correctly predicted positive observations to all observations of the class. More specifically, Recall = True Positives / (True Positives + False Negatives).\n",
    "\n",
    "The metric emphasizes minimizing false negatives, which is applicable to evaluate our solution because we want to minimize the amount of undetected pneumonia lungs (hence why we need a low false negative rate). Having a low false negative rate is important in this situation because a diagnosis of a \"Normal\" lung condition when it is in fact penumonia is detrimental and possibly fatal to the patient. On the same token, it's necessary that healthy lungs are not misclassified as pneumonia because that would create unnecessary issues for a healthy patient. Because of this, we chose to use recall, implemented below, to evaluate our CNN solution.\n",
    "\n",
    "Source: https://www.analyticsvidhya.com/blog/2020/10/how-to-choose-evaluation-metrics-for-classification-model/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "\n",
    "#recall implementation from: https://datascience.stackexchange.com/questions/45165/how-to-get-accuracy-f1-precision-and-recall-for-a-keras-model\n",
    "def recall_m(y_true, y_pred):\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "        recall = true_positives / (possible_positives + K.epsilon())\n",
    "        return recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dividing Data\n",
    "\n",
    "We are using 10-fold Cross Validation in order to split up the data into training and test sets. We chose to use this method because almost 3/4 of our the lungs in our dataset are labeled as having pneumonia, whereas only 1/4 is labeled as healthy. Thus, if we did a random split/shuffle, there may be disproportionate amounts of pneumonia classification in the training variables, which would make the classification for the testing data less accurate. With \n",
    "Stratified 10-fold cross validation, we can make a more effective model and also help with generalizing. It allows us to select training and testing sets while also decreasing overall variance because of the 10 folds, which will fit each CNN on each fold. After fitting the model on 10 folds, we can evaluate it on a test set created using an 80-20 split. This would be a realistic measuring of a real-world application of the algorithm because with smaller test sets, there is higher variance. Stratified cross validation reduces this variance by averaging over k different partitions, so the performance estimate is less sensitive to the partitioning of the data. We also chose 10 folds because this value has been shown empirically to yield test error rate estimates that suffer neither from excessively high bias nor from very high variance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This block is essentially not using the separated test and target folders from \n",
    "# ./Coronahack-Chest-XRay-Dataset/ directory. I'm simply training/splitting on the metadata.csv\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils import to_categorical\n",
    "import tensorflow.keras as keras\n",
    "import tensorflow as tf\n",
    "\n",
    "tf.random.set_seed(2)\n",
    "np.random.seed(0) # using this to help make results reproducible\n",
    "\n",
    "data = pd.read_csv('Chest_xray_Corona_Metadata.csv')\n",
    "\n",
    "#shuffle data\n",
    "data = data.sample(frac=1)\n",
    "\n",
    "# Define features and target\n",
    "X_ = data.drop(\"Label\", axis=1)\n",
    "y_ = data[\"Label\"]\n",
    "\n",
    "#perform Stratified 10-fold cross validation\n",
    "kfold = StratifiedKFold(n_splits=10, random_state=42, shuffle=True).split(X_, y_)\n",
    "\n",
    "# Split it into train / test subset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_, y_, test_size=0.20, random_state=0)\n",
    "\n",
    "X_train_df = pd.DataFrame(X_train, columns= data.columns)\n",
    "X_test_df = pd.DataFrame(X_test, columns= data.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling (6 pts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [<b>1.5 points</b>]  Setup the training to use data expansion in Keras. Explain why the chosen data expansion techniques are appropriate for your dataset. \n",
    "- [<b>2 points</b>] Create a convolutional neural network to use on your data using Keras. Investigate at least two different convolutional network architectures (and investigate changing some parameters of each architecture--at minimum have two variations of each network for a total of four models trained). Use the method of cross validation and evaluation metric that you argued for at the beginning of the lab. Visualize the performance of the training and validation sets per iteration (use the \"history\" parameter of Keras).\n",
    "- [<b>1.5 points</b>] Visualize the final results of the CNNs and interpret the performance. Use proper statistics as appropriate, especially for comparing models. \n",
    "- [<b>1 points</b>] Compare the performance of your convolutional network to a standard multi-layer perceptron (MLP) using the receiver operating characteristic and area under the curve. Use proper statistical comparison techniques.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exceptional Work (1 pt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- You have free reign to provide additional analyses. \n",
    "- One idea (<b>required for 7000 level students</b>): Use transfer learning to pre-train the weights of your initial layers of your CNN. Compare the performance when using transfer learning to training from scratch in terms of classification performance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
